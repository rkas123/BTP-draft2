{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cca7da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c269eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTOTXT = \"MobileNetSSD_deploy.prototxt\"\n",
    "MODEL = \"MobileNetSSD_deploy.caffemodel\"\n",
    "INP_VIDEO_PATH = 'dog.jpg'\n",
    "OUT_VIDEO_PATH = 'dog_detection.jpg'\n",
    "GPU_SUPPORT = 0\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\",  \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd86d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)\n",
    "if GPU_SUPPORT:\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b29acdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     ret, frame = ccaap.read()\n",
    "#     if not ret:\n",
    "#        break\n",
    "def SSD(img_path):\n",
    "    frame = cv2.imread(img_path)\n",
    "    h, w = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), 127.5)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            label = \"{}: {:.2f}%\".format(CLASSES[idx],confidence*100)\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY),    COLORS[idx], 2)\n",
    "            y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "            cv2.putText(frame, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "            cv2.imwrite(img_path + '2' +'.jpg', frame)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df8f9b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.23862528800964355 seconds\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "SSD('rupesj.jpeg')\n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0be05227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8103949",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    global t\n",
    "    label = str(classes[class_id]) + ' ' + str(format(confidence, '.2f'))\n",
    "    if t == 0:\n",
    "        color = [255, 0, 0]\n",
    "    elif t == 1:\n",
    "        color = [0, 255, 0]\n",
    "    elif t == 2:\n",
    "        color = [0, 0, 255]\n",
    "    else:\n",
    "        color = [0, 255, 0]\n",
    "    # print(color)\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    t += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a39313f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_objects(image, image_name):\n",
    "    global classes\n",
    "    objects, positions, coords = [], [], []\n",
    "    image = cv2.resize(image, (400, 300))\n",
    "    # image = cv2.resize(cv2.imread(r'dog.jpg'), (400, 300))\n",
    "\n",
    "    Width = image.shape[1]\n",
    "    Height = image.shape[0]\n",
    "    scale = 0.00392\n",
    "\n",
    "    with open('./yolov3.txt', 'r') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "    # print(COLORS)\n",
    "    net = cv2.dnn.readNet('./yolov3.cfg', './yolov3.weights')\n",
    "    blob = cv2.dnn.blobFromImage(image, scale, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(get_output_layers(net))\n",
    "    # print(outs)\n",
    "    # print(outs[2].shape, len(outs))\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    conf_threshold = 0.5\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    loop = 0\n",
    "    for out in outs:\n",
    "        loop += 1\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                # print('\\n\\n\\n', loop, detection)\n",
    "                center_x = int(detection[0] * Width)\n",
    "                center_y = int(detection[1] * Height)\n",
    "                w = int(detection[2] * Width)\n",
    "                h = int(detection[3] * Height)\n",
    "                x = center_x - w / 2\n",
    "                y = center_y - h / 2\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, w, h])\n",
    "\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    total_time = time.time() - start\n",
    "    print(total_time)\n",
    "\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        x = box[0]\n",
    "        y = box[1]\n",
    "        w = box[2]\n",
    "        h = box[3]\n",
    "        draw_prediction(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "        print(classes[class_ids[i]] + ' detected with an accuracy of ' + str(confidences[i] * 100) + ' %')\n",
    "        objects.append(classes[class_ids[i]])\n",
    "\n",
    "        center_x = x + (w / 2)\n",
    "        # center_y = (y + h) / 2\n",
    "        # print(\"co \", x, y, w, h, image.shape)\n",
    "        coords.append([x, y, w, h])\n",
    "        if center_x < 133:\n",
    "            print(\"left\")\n",
    "            print(center_x)\n",
    "            positions.append('left')\n",
    "        elif center_x > 266:\n",
    "\n",
    "            positions.append('right')\n",
    "            print(center_x)\n",
    "            print(\"right\")\n",
    "        else:\n",
    "            print(\"front\")\n",
    "            positions.append('front')\n",
    "\n",
    "    cv2.imwrite(image_name + '3'+\".jpg\", image)\n",
    "    # cv2.imshow('a', image)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "    return objects, coords, positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ce3b214",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "classes = None\n",
    "objects, positions, coords = [], [], []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be707ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'rupesj.jpeg'\n",
    "img = cv2.imread(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b221e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6729645729064941\n",
      "chair detected with an accuracy of 99.27465319633484 %\n",
      "311.0\n",
      "right\n",
      "person detected with an accuracy of 97.5334882736206 %\n",
      "left\n",
      "85.0\n",
      "chair detected with an accuracy of 81.11701011657715 %\n",
      "front\n",
      "person detected with an accuracy of 61.13331913948059 %\n",
      "290.0\n",
      "right\n",
      "chair detected with an accuracy of 59.875690937042236 %\n",
      "left\n",
      "53.0\n",
      "book detected with an accuracy of 56.91693425178528 %\n",
      "front\n",
      "book detected with an accuracy of 52.10632681846619 %\n",
      "front\n",
      "book detected with an accuracy of 51.14923715591431 %\n",
      "front\n",
      "Execution time: 1.0090017318725586 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "st = time.time()\n",
    "detect_objects(img, image_name)\n",
    "et = time.time()\n",
    "\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9442bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
